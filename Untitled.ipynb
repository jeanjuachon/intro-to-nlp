{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4656fbff-6b80-4c70-99b3-f68dcc62b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests\n",
    "import requests\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "#data, strucuture and maths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import string\n",
    "from  more_itertools import unique_everseen\n",
    "import random\n",
    "\n",
    "#progress,performance and management\n",
    "import tqdm\n",
    "import threading\n",
    "import os\n",
    "import ssl\n",
    "from IPython.display import clear_output\n",
    "import platform\n",
    "import os\n",
    "\n",
    "#time\n",
    "from time import sleep\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b99e1ef-00b9-4aae-9e6d-de436e154a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusixmatchScraper():\n",
    "    \n",
    "    \"\"\"This class allows you to scrape the lyrics for an artist who has a presence on Musixmatch\n",
    "    \n",
    "    An instance of the class needs to be instantiated with an artist URL e.g.\n",
    "    \n",
    "    https://www.musixmatch.com/artist/Bob-Dylan\n",
    "    \n",
    "    The default number of songs to scrape is 50\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,artist_url,genre_label):\n",
    "\n",
    "        self.artist_url = artist_url #artists URL as attribute\n",
    "        \n",
    "        self.artist = artist_url.split('artist/')[-1] #artist string as attribute\n",
    "        \n",
    "        self.genre_label = genre_label #genre as attribute\n",
    "         \n",
    "        self.song_l = [] #empty list to populate lyrics\n",
    "                        \n",
    "    def _get_html(self,url):\n",
    "        \n",
    "        \"\"\"Uses Beatiful Soup to extract html from a url. Returns a soup object \"\"\"\n",
    "\n",
    "        headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'}\n",
    "\n",
    "        req = Request(url, headers=headers)\n",
    "\n",
    "        return BeautifulSoup(urlopen(req).read(), 'html.parser')\n",
    "\n",
    "    def _multithreadCompile(self,thread_count,iteration_list,func):\n",
    "        \n",
    "        \"\"\"a function that compiles an iteration list to prepare\n",
    "        multi threadding\"\"\"\n",
    "\n",
    "        jobs = []\n",
    "\n",
    "        #distribute iteration list to batches and append to jobs list\n",
    "        batches = [i.tolist() for i in np.array_split(iteration_list,thread_count)]\n",
    "\n",
    "        for i in range(len(batches)):\n",
    "\n",
    "            jobs.append(threading.Thread(target=func,args=[batches[i]]))\n",
    "            \n",
    "        return jobs\n",
    "\n",
    "    def _multithreadExecute(self,jobs):\n",
    "        \n",
    "        \"\"\"executes the multi-threadding loop\"\"\"\n",
    "\n",
    "        # Start the threads\n",
    "        for j in jobs:\n",
    "    \n",
    "            j.start()\n",
    "\n",
    "        # Ensure all of the threads have finished\n",
    "        for j in jobs:\n",
    "            j.join()\n",
    "        return\n",
    "    \n",
    "    def _getpageUrls(self,url):\n",
    "        \n",
    "        \"\"\"Gets all the links from an artist page\"\"\"\n",
    "     \n",
    "        html = self._get_html(url) #gets html for current page\n",
    "        \n",
    "        songs = html.find_all('h2',{'class':'media-card-title'}) #element for song\n",
    "        \n",
    "        #loop through and extract urls for all songs in soup object\n",
    "        song_urls = ['https://www.musixmatch.com'+i.find('a')['href'] for i in songs] \n",
    "        \n",
    "        #return list of song urls\n",
    "        return [i for i in song_urls if 'album' not in i]\n",
    "\n",
    "\n",
    "    def _getLyrics(self,song_url):\n",
    "        \n",
    "        \"\"\"Extracts lyrics from a song url. Duplicated lines are removed e.g. chorus lines\n",
    "        Only unique lyrics are returned\"\"\"\n",
    "    \n",
    "        html = self._get_html(song_url) #get html for current page\n",
    "\n",
    "        #find all elements containing lyrics\n",
    "        element = html.find_all('span',{'class':'lyrics__content__ok'})\n",
    "\n",
    "        #numbe of elements to loop through\n",
    "        element_loop = len(element)\n",
    "\n",
    "        song_lyrics = [] #empty list for song lyrics\n",
    "\n",
    "        #extract song lyrics\n",
    "        song_lyrics_raw = [element[i].text.split('\\n') for i in range(element_loop)]\n",
    "\n",
    "        #flatten list of lists\n",
    "        song_lyrics_raw = [i for sublist in song_lyrics_raw for i in sublist]\n",
    "\n",
    "        #retain only unique lines in lyrics\n",
    "        song_lyrics.extend(list(dict.fromkeys(song_lyrics_raw)))\n",
    "\n",
    "        #join list and remove empty elements\n",
    "        song_lyrics = ' '.join([i for i in song_lyrics if len(i) >0])\n",
    "\n",
    "        return song_lyrics #return song lyrics\n",
    "    \n",
    "    def _getAllpageUrls(self,target=50):\n",
    "        \n",
    "        \"\"\"Generates page urls for artist. There are 15 songs on each page\"\"\"\n",
    "        \n",
    "        loops = int(target/15) #specifcy how many loops needed\n",
    "        \n",
    "        #generate urls\n",
    "        artist_urls = [self.artist_url+'/'+str(i+1) for i in range(loops)]\n",
    "        \n",
    "        all_song_urls = [] #empty list for all song urls\n",
    "        \n",
    "        for i in artist_urls: #loop through and get all song urls for all pages\n",
    "            \n",
    "            all_song_urls.extend(self._getpageUrls(i))\n",
    "        \n",
    "        return all_song_urls\n",
    "              \n",
    "    def _extractData(self,all_song_urls):\n",
    "        \n",
    "        \"\"\"Extracts data from all song urls\"\"\"\n",
    "    \n",
    "        for i in tqdm_notebook(range(len(all_song_urls))): #loop through all song urls\n",
    "            \n",
    "            try:\n",
    "                #get lyrics\n",
    "                song_lyrics = self._getLyrics(all_song_urls[i])\n",
    "                \n",
    "                #get song title\n",
    "                song_title = all_song_urls[i].split('/')[-1]\n",
    "\n",
    "                #create DataFrame\n",
    "                song_df = pd.DataFrame([(self.artist,song_title,song_lyrics)],columns=['artist','song','lyrics'])\n",
    "                \n",
    "                #append DataFrame to master list\n",
    "                self.song_l.append(song_df)\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return \n",
    "    \n",
    "    def Run(self,target):\n",
    "        \n",
    "        \"\"\"Executes all methods above\"\"\"\n",
    "       \n",
    "        self.all_song_urls = self._getAllpageUrls(target) #get page URL's to get target number of songs\n",
    "\n",
    "        #multi-threaded scraping of all song urls\n",
    "        self._multithreadExecute(self._multithreadCompile(5,self.all_song_urls,self._extractData))\n",
    "\n",
    "        try:\n",
    "            df_final = pd.concat([i for i in self.song_l]) #concatenate all song Df's\n",
    "\n",
    "            df_final.reset_index(drop=True,inplace=True) #reset index\n",
    "            \n",
    "            self.df = df_final[df_final.lyrics.str.len() > 0] #drop any songs with no lyrics or failed scrapes\n",
    "\n",
    "            self.df['genre'] = self.genre_label #add genre column\n",
    "            \n",
    "            return self.df\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c9a064-7ff6-4116-bec9-2eecfbde62f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bulk_lyrics = []\n",
    "\n",
    "# #band/artist urls and genres - as tuples\n",
    "# bands = [('https://www.musixmatch.com/artist/Drake','drake-rap'),\n",
    "#          ('https://www.musixmatch.com/artist/Kanye-West','kanye-rap')]\n",
    "\n",
    "# #loop through each band\n",
    "# for band in bands:\n",
    "    \n",
    "#     #instantate class for band using url and genre label\n",
    "#     scraper = MusixmatchScraper(band[0],genre_label=band[1])\n",
    "    \n",
    "#     #run scraper and set target number of songs to scrape\n",
    "#     scraper.Run(target=60)\n",
    "    \n",
    "#     #append to bulk lyrics\n",
    "#     bulk_lyrics.append(scraper.df)\n",
    "    \n",
    "# #concatenate list of DataFrame's to one DataFrame\n",
    "# df = pd.concat([i for i in bulk_lyrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd77e24-9038-47e2-8d88-8c82b13e9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:128: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d23d37516bf4ae3a5b6169f5ca0a39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912488b4f3a642d9948e3be23d7820c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643cb0e72f8e414d8577e0992ba99ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985c2b6eb88c406a8bb16f762a8e7045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e70961eb2aa4478beb1482e1aeac136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scraper = MusixmatchScraper('https://www.musixmatch.com/artist/Jack-Johnson','folk')\n",
    "scraper.Run(target = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74346415-714d-4fb7-a67f-e313d4f0a23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MusixmatchScraper' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f2/wxwp9zk96mn2jg7jc6hjvxbh0000gn/T/ipykernel_53002/1631251927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MusixmatchScraper' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "scraper.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0edf0cf-af51-4acf-a079-6d73c93baeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
